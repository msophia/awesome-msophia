{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **BUT** : scrapper les articles d'abidjan.net les stucturer et les stocker dans sqlserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup #beautifulsoup et scrapy sont les outils de webscraping \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_url =\"https://news.abidjan.net/\"    #initialisation avec l'url du site à scrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uClient = uReq(quotes_url) \n",
    "\n",
    "page_html= uClient.read() # lire la page en html brut\n",
    "\n",
    "uClient.close() #fermeture\n",
    "\n",
    "page_soup = soup(page_html,\"html.parser\") #rend le code plus lisible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = page_soup.find_all(\"a\",attrs={\"class\":\"ebloc-default\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = page_soup.find_all(\"h4\", {\"class\":\"section-title\",\"style\":\"margin-bottom: 10px\"})\n",
    "categorie = {i.get_text() for i in categories} #recuperation des catégories"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dans cette etapes\n",
    "- je vais recuperer les articles par catégorier,\n",
    "- effectuer des transformations(supprimer les accents,ecrire en miniscule)\n",
    "- stocker les données dans un dataframe(news_items) avec les colonnes \"date\",\"url\",\"titre\",\"vignette\",\"source\",\"categorie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_format = \"https://news.abidjan.net/articles/{}\"   \n",
    "news_items =pd.DataFrame(columns=[\"date\",\"url\",\"titre\",\"vignette\",\"source\",\"categorie\"])\n",
    "\n",
    "for category in categorie:\n",
    "    category_page = uReq(url_format.format(category.replace(\" \",\"-\").lower().replace(\"é\",\"e\"))).read()\n",
    "    category_soup = soup(category_page, \"html.parser\")    \n",
    "    pages_num = category_soup.find_all(\"a\",attrs={\"class\":\"page-link\"})\n",
    "    url_art = \"https://news.abidjan.net/articles/\"+category.replace(\" \",\"-\").lower().replace(\"é\",\"e\")+\"?page={}\"\n",
    "    if len(pages_num) >= 3:\n",
    "        pages_num_max = int(category_soup.find_all(\"a\",attrs={\"class\":\"page-link\"})[-2].get_text())            \n",
    "        \n",
    "    else:\n",
    "        pages_num_max = 1\n",
    "        \n",
    "    for i in range(1,pages_num_max+1):        \n",
    "            articles_pages= uReq(url_art.format(i)).read()\n",
    "            articles_soup = soup(articles_pages, \"html.parser\")\n",
    "            articles = articles_soup.find_all(\"a\",attrs={\"class\":\"grd-item ebloc-default\"})     \n",
    "            for article in articles:                                          \n",
    "                url = \"https://news.abidjan.net\"+article.attrs['href']\n",
    "                infos =article.find(\"span\", {\"class\": \"infos\"}).get_text().split(\"-\")\n",
    "                if len(infos)==2:\n",
    "                    source = infos[0].strip()\n",
    "                    date = infos[1].strip()\n",
    "                elif len(infos) >2:\n",
    "                    source = '-'.join(infos[:-1]).strip()\n",
    "                    date = infos[-1].strip()\n",
    "                    \n",
    "                vignette = article.find(\"img\")[\"data-original\"]\n",
    "                \n",
    "                    \n",
    "                titre = article.find(\"span\", {\"class\": \"title\"}).get_text()\n",
    "                #clean_titre = titre.replace(\" \",\"-\")\n",
    "                #if \"https\" in vignette:\n",
    "                   # clean_vignette = vignette\n",
    "                #else:\n",
    "                    #clean_vignette = \"Aucune vignette\"\n",
    "                data = {\n",
    "                        \"date\":date,\n",
    "                        \"url\":url,\n",
    "                        \"titre\":titre,\n",
    "                        \"vignette\":vignette,\n",
    "                        \"source\":source,\n",
    "                        \"categorie\":category,\n",
    "                        #\"clean_titre\":clean_titre,\n",
    "                        #\"clean_vignette\":clean_vignette                       \n",
    "                        }\n",
    "                news_items = news_items.append(data,ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: vignette, dtype: object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_items)\n",
    "news_items[\"vignette\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mois = {\n",
    "    \"janvier\": \"01\", \n",
    "    \"février\": \"02\",\n",
    "    \"mars\": \"03\", \n",
    "    'avril': \"04\",\n",
    "    'mai': \"05\", \n",
    "    'juin': \"06\", \n",
    "    'juillet': \"07\",\n",
    "    \"août\": \"08\",\n",
    "    'septembre': \"09\",\n",
    "    'octobre': \"10\",\n",
    "    'novembre': \"11\", \n",
    "    'décembre': \"12\"}\n",
    "\n",
    "Mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def convert_mois(date):\n",
    "    mth = date.split()\n",
    "    mth[1] = Mois[mth[1]]\n",
    "    return datetime.strptime(\"/\".join(mth),\"%m/%d/%Y\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_items[news_items[\"date\"]==\"Côte d’Ivoire\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_items[\"date\"]=news_items[\"date\"].apply(convert_mois)\n",
    "news_items[\"date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAPE DE STOCKAGE\n",
    "etape d'enregistrement des données structurée dans notre base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost:3308/{db}\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"\",\n",
    "                               db=\"article_abidjan.net\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_items.to_sql('articles_06102021', con = engine, if_exists = 'append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
